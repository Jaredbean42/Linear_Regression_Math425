set.seed(42) #This ensures the randomness is the "same" everytime if you play the entire R-chunk as one entire piece of code. If you run lines separately, your data might not come out the same every time. You can pick any integer value you want for set.seed. Each choice produces a different sample, so you might want to play around with a few different choices.
## To begin, decide on your sample size. (You may have to revise it later to ensure all values in your lm(...) are significant.)
n <- 500
## Then, create 10 X-variables using functions like rnorm(n, mean, sd), rchisq(n, df), rf(n, df1, df2), rt(n, df), rbeta(n, a, b), runif(n, a, b) or sample(c(1,0), n, replace=TRUE)... ## To see what any of these functions do, run codes like hist(rchisq(n, 3)). These functions are simply allowing you to get a random sample of x-values. But the way you choose your x-values can have quite an impact on what the final scatterplot of the data will look like.
x2 <- runif(n, -8, 8) # TRUE x axis
x5 <- sample(c(0,1), n, replace=TRUE) #true switch for red parabola
x3 <- sample(c(0,1), n, replace=TRUE) #true switch for green line
#x3[x5==1] <- 0 #This makes it so they can't both be on
x1 <- runif(n, -8, 8) #replace this
x4 <- runif(n, -8, 8) #experamental switch pt1
x6 <- runif(n, -8, 8) #exp switch pt2
x7 <- runif(n, -8, 8) #replace this
x8 <- runif(n, -8, 8) #replace this
x9 <- runif(n, -8, 8) #replace this
x10 <- runif(n, -8, 8) #replace this
z1 <- 0 #true switch that is impossible to find now
z1[x4>3 & x6<3] <- 0
x2 <- ( x9 / x10)
# GOLDEN??? What is up with adding in switches. also adding doesnt do anything
#Too much sauce ruins the lm so be carful. multiply and divide
## Then, create betas, sigma, normal error terms and y
#Primary quad
beta0 <- -2
beta1 <- 0.001
beta3 <- 0.01
#Changes needed for next quadratic
beta4 <- 4
beta5 <- -0.001
beta6 <- -0.02
#changes needed for a green desc line
beta7 <- 2
beta8 <- -0.201
beta9 <- -0.01
#changes needed for positive orange line
beta10 <- -4
beta11 <- 0.401
beta12 <- 0.02
sigma <- 1.42 #change to whatever positive number you want
################################
# You ARE NOT ALLOWED to change this part:
epsilon_i <- rnorm(n, 0, sigma)
################################
#An example of how to make Y...
# y <-  beta0 + beta1*X1 + beta2*X2 + beta3*X4*X2 + epsilon_i
y <- beta0 + beta1*x2 + beta3*x2^2 +  #primary quadratic blue
(beta4 + beta5*x2 + beta6*x2^2)*x5 + #second quadratic red (x5 is switch)
(beta7 + beta8*x2 + beta9*x2^2)*x3 + #decreasing line green
(beta10 + beta11*x2 + beta12*x2^2)*x3*x5 #increasing orange line
+ epsilon_i
#...edit this code and replace it with your model. Don't forget the + epsilon_i!
## Now, you need to load your x-variables and y-variable
## into a data set.
# You can include Y' or X' instead of Y or X if you wish.
# Remember, only these functions are allowed when transforming
# variables: 1/Y^2, 1/Y, log(Y), sqrt(Y), sqrt(sqrt(Y)), Y^2, Y^3, 1/X^2, 1/X, log(X), sqrt(X), sqrt(sqrt(X)), X^2, X^3, X^4, X^5.
#########################################################
# ILLEGAL: Y = (beta0 + beta1*X5)^2 + epsilon_i #########
#########################################################
# Legal: sqrt(Y) = beta0 + beta1*X5^2 + epsilon_i #######
#########################################################
# You can only transform individual terms, not groups of terms.
# And the beta's cannot be part of the x-transformations.
# This loads your data into a data set:
rbdata <- data.frame(y, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10)
#Now fit your model to make sure it comes out significant:
#Fixed?
mylm <- lm(y ~ x2 + I(x2^2) +  #primary quadratic blue
(x2 + I(x2^2))*x5 + #second quadratic red (x5 is switch)
(x2 + I(x2^2))*x3 + #decreasing line green
(x2 + I(x2^2))*x3*x5)
#Previous got error?
# mylm <- lm(y ~ I(x2^2) +#first quad blue REMOVED x2
#            x5 + I(x2^2):x5 +# second quad red REMOVED x2:x5
#            x3 + x2:x3 + #Decreasing line green
#            x3:x5 + x2:x3:x5 #increasing orange line
#
#            , data=rbdata) #edit this code to be your true model
summary(mylm)
#all p-values must be significant
#the R^2 value must be greater than or equal to 0.30.
# Once you are done with creating your model, and have successfully
# graphed it (see below), un-comment the following `write.csv` code,
# then, PLAY this ENTIRE R-chunk to write your data to a csv.
# write.csv(rbdata, "rbdata.csv", row.names=FALSE)
# The above code writes the dataset to your "current directory"
# To see where that is, use: getwd() in your Console.
# Find the rbdata.csv data set and upload it to I-Learn.
#Now fit your model to make sure it comes out significant:
#Fixed?
mylm <- lm(y ~ x2 + I(x2^2) +  #primary quadratic blue
(x2 + I(x2^2))*x5 + #second quadratic red (x5 is switch)
(x2 + I(x2^2))*x3 + #decreasing line green
(x2 + I(x2^2))*x3*x5)
#Previous got error?
# mylm <- lm(y ~ I(x2^2) +#first quad blue REMOVED x2
#            x5 + I(x2^2):x5 +# second quad red REMOVED x2:x5
#            x3 + x2:x3 + #Decreasing line green
#            x3:x5 + x2:x3:x5 #increasing orange line
#
#            , data=rbdata) #edit this code to be your true model
summary(mylm)
plot(y~x2,
data=rbdata,
xlim=c(-8,8),
ylim=c(-4,4),
col=interaction(x5, x3)
)
x5=0
x3=0
curve(beta0 + beta1*x2 + beta3*x2^2 +  #primary quadratic blue
(beta4 + beta5*x2 + beta6*x2^2)*x5 + #second quadratic red (x5 is switch)
(beta7 + beta8*x2 + beta9*x2^2)*x3 + #decreasing line green
(beta10 + beta11*x2 + beta12*x2^2)*x3*x5 #orange line
, add=TRUE, xname="x2", col="steelblue", lwd=5, lty=3)
x5=1
x3=0
curve(beta0 + beta1*x2 + beta3*x2^2 +  #primary quadratic blue
(beta4 + beta5*x2 + beta6*x2^2)*x5 + #second quadratic red (x5 is switch)
(beta7 + beta8*x2 + beta9*x2^2)*x3 + #decreasing line green
(beta10 + beta11*x2 + beta12*x2^2)*x3*x5 #orange line
, add=TRUE, xname="x2", col="red", lwd=5, lty=3)
x5=0
x3=1
curve(beta0 + beta1*x2 + beta3*x2^2 +  #primary quadratic blue
(beta4 + beta5*x2 + beta6*x2^2)*x5 + #second quadratic red (x5 is switch)
(beta7 + beta8*x2 + beta9*x2^2)*x3 + #decreasing line green
(beta10 + beta11*x2 + beta12*x2^2)*x3*x5 #orange line
, add=TRUE, xname="x2", col="green", lwd=5, lty=3)
x5=1
x3=1
curve(beta0 + beta1*x2 + beta3*x2^2 +  #primary quadratic blue
(beta4 + beta5*x2 + beta6*x2^2)*x5 + #second quadratic red (x5 is switch)
(beta7 + beta8*x2 + beta9*x2^2)*x3 + #decreasing line green
(beta10 + beta11*x2 + beta12*x2^2)*x3*x5 #orange line
, add=TRUE, xname="x2", col="orange", lwd=5, lty=3)
#To make lm curves match the b on the regression
b <- coef(mylm)
#This is predicted curves
x5=0
x3=0
curve(b[1] + b[2]*x2 + b[3]*x2^2 + b[4]*x5 + b[5]*x3 + b[6]*x2*x5 +
b[7]*x2^2*x5 + b[8]*x2*x3 + b[9]*x2^2*x3 + b[10]*x5*x3 + b[11]*x2*x5*x3 +
b[12]*x2^2*x5*x3,
add=TRUE, xname="x2", col="black", lwd=1)
x5=1
x3=0
curve(b[1] + b[2]*x2 + b[3]*x2^2 + b[4]*x5 + b[5]*x3 + b[6]*x2*x5 +
b[7]*x2^2*x5 + b[8]*x2*x3 + b[9]*x2^2*x3 + b[10]*x5*x3 + b[11]*x2*x5*x3 +
b[12]*x2^2*x5*x3,
add=TRUE, xname="x2", col="black", lwd=1)
x5=0
x3=1
curve(b[1] + b[2]*x2 + b[3]*x2^2 + b[4]*x5 + b[5]*x3 + b[6]*x2*x5 +
b[7]*x2^2*x5 + b[8]*x2*x3 + b[9]*x2^2*x3 + b[10]*x5*x3 + b[11]*x2*x5*x3 +
b[12]*x2^2*x5*x3,
add=TRUE, xname="x2", col="black", lwd=1)
x5=1
x3=1
curve(b[1] + b[2]*x2 + b[3]*x2^2 + b[4]*x5 + b[5]*x3 + b[6]*x2*x5 +
b[7]*x2^2*x5 + b[8]*x2*x3 + b[9]*x2^2*x3 + b[10]*x5*x3 + b[11]*x2*x5*x3 +
b[12]*x2^2*x5*x3,
add=TRUE, xname="x2", col="black", lwd=1)
#add legend
legend("bottomright",
legend = c("mylm lines"),
col = "black",
lwd = 2)
